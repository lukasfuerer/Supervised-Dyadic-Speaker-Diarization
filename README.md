# Supervised-Dyadic-Speaker-Diarization

Speaker Diarization concerns with creating a stream of speaker identity from an audio file. Here, an overview is provided and important steps are described when using the Matlab function Diarize(). Using the Audio Analysis Library (Giannakopoulos & Pikrakis, 2014), a Matlab based Voice Activity Detection System (Segbroeck, Tsiartas, & Narayanan, 2013) and a function to calculate the number of bins of histograms (Cotton, 2009, via File Exchange), the function trains a random forest classifier (per Dyad) to diarize speakers in dyadic audio. The classifier is trained with a manually created Learning Set holding speaker annotations with timestamps (of utterances) for a subset of sessions.

The function assumes Dyads and Sessions. Please provide the following filename structure: DyadID_SessionID.wav (audio), DyadID_SessionID.txt (learning set). DO NOT USE ‘_’ (underline) IN DyadID OR SessionID.
Note: if only one audio file exists per dyad, please add ‘_1’ (SessionID) to each file.

*The following section will guide you through the necessary steps:*
1.	Create a Learning Set: A learning set consists of one or more txt files with three columns each (1. Start Time of Utterance in seconds, 2. Stop Time of Utterance in seconds, 3. Speaker Annotation). Concerning the speaker annotation, use 1 and 2 to indicate the different speakers. Learning Set files have the following file name structure: PatientID_SessionID.txt. An example Learning Set is provided. They can easily be created with Audacity (http://audacity.sourceforge.net/download/). It allows for annotating labels (Region Labels) in audio and exporting them as txt (https://manual.audacityteam.org/man/label_tracks.html). For one Dyad the Learning Set can be comprised of labels stemming from multiple sessions of the respective Dyad, all in SEPERATE files with the above mentioned filename structure. When more than one learning set file exists per dyad, the algorithm will use all learning sets of a dyad to train the classifier. Save all learning set files in one directory.
2.	Add the repository to your matlab path. Call the function with Inputs: AudioDirectory (where audio files are provided, folder name as string), LearningSetDirectory (where Learning Set files are provided, folder name as string), vadP1, vadP2 and sdWin. vadP1 (speech-noise-threshold) and vadP2 (speech region smoothing) are customizeable parameters for the Voice Activity Detection, the authors have set the default vadP1 = 0.1 / vadP2 = 20 (Segbroeck, Tsiartas, & Narayanan, 2013). sdWin sets the window length that is used in the Silence Detection when determining the dynamic silence threshold. sdWin = 0.01 is recommended as a starting point. If no input for parameters is given, default values are assumed.
3.	The function creates the following folders on the level of the AudioDirectory to save the output: diarizefeatures (where feature files will be stored), diarizemodels (where diarization models will be stored) and diarizeprediction (where the final prediction files are stored). The output prediction file contains 5 variables. Time = time in seconds, silence = output of SilenceDetection (dynamic intensity thresholding, 1=silence, 0=not silence), vad = output from voice activity detection (Segbroeck et al., 2013, 1=voiced window, 0=unvoiced window), prediction = decision of random forest classifier (1=speaker one, 2=speaker two), AggregatedDiarization (AD, 0=silence, 1=speaker one, 2=speaker two) = combination of output streams (if silence == 1, then AD = 0 -> if silence == 0, then AD = vad -> if silence == 0 & vad == 1, then AD = prediction).

The figure Diarize Flow.pdf provides an overview over the functional statements treated.

*Dependencies (included in the package):*
- Giannakopoulos, T., & Pikrakis, A. (2014). Introduction to audio analysis: A MATLAB approach (First edition). Kidlington, Oxford: Academic Press is an imprint of Elsevier.
- Segbroeck, M. V., Tsiartas, A., & Narayanan, S. (2013). A Robust Frontend for VAD: Exploiting Contextual, Discriminative and Spectral Cues of Human Voice. INTERSPEECH, 5.
- calcbins.mat, Richard Cotton (2009): https://ch.mathworks.com/matlabcentral/fileexchange/21033-calculate-number-of-bins-for-histogram?focused=5103618&tab=function
- Example Audio and Example Learningset stemming from the EMRAI synthetic diarization corpus: Edwards, E., Brenndoerfer, M., Robinson, A., Sadoughi, N., Finley, G. P., Korenevsky, M., Axtmann, N. & Suendermann-Oeft, D. (2018, September). A Free Synthetic Corpus for Speaker Diarization Research. In International Conference on Speech and Computer (pp. 113-122). Springer, Cham.

Correspondig author:
Lukas Fürer, lukas.fuerer@posteo.net
